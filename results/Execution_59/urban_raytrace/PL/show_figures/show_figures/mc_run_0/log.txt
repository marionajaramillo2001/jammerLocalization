Monte Carlo Run 1/1 with Seed: 42
Configuration:
path: /Users/marionajaramillocivill/Documents/GitHub/GNSSjamLoc/RT41/obs_time_1/
time_t: 0
test_ratio: 0.2
data_preprocessing: 2
noise: 1
meas_noise_var: 1
betas: True
input_dim: 2
layer_wid: [500, 256, 128, 1]
nonlinearity: leaky_relu
gamma: 2
num_nodes: 10
local_epochs_nn: 20
local_epochs_pl: 20
local_epochs_apbm: 20
num_rounds_nn: 40
num_rounds_pl: 40
num_rounds_apbm: 40
batch_size: 8
lr_optimizer_nn: 0.001
lr_optimizer_theta: 0.5
lr_optimizer_P0: 0.01
lr_optimizer_gamma: 0.01
weight_decay_optimizer_nn: 0
model_type: PL
num_obs: 1000
Training the NN model...
Train losses per round (NN): [array(0., dtype=float32), array(0., dtype=float32), array(0., dtype=float32), array(0., dtype=float32), array(0., dtype=float32), array(0., dtype=float32), array(0., dtype=float32), array(0., dtype=float32), array(0., dtype=float32), array(0., dtype=float32), array(0., dtype=float32), array(0., dtype=float32), array(0., dtype=float32), array(0., dtype=float32), array(0., dtype=float32), array(0., dtype=float32), array(0., dtype=float32), array(0., dtype=float32), array(0., dtype=float32), array(0., dtype=float32), array(0., dtype=float32), array(0., dtype=float32), array(0., dtype=float32), array(0., dtype=float32), array(0., dtype=float32), array(0., dtype=float32), array(0., dtype=float32), array(0., dtype=float32), array(0., dtype=float32), array(0., dtype=float32), array(0., dtype=float32), array(0., dtype=float32), array(0., dtype=float32), array(0., dtype=float32), array(0., dtype=float32), array(0., dtype=float32), array(0., dtype=float32), array(0., dtype=float32), array(0., dtype=float32), array(0., dtype=float32)]
Initial theta: [470. 468.]
Training the PL model...
Round 0: test_loss = 1.969499
Round %d: (0, (29.318458656637073, array([469.25862013, 470.95714703])))
Round 1: test_loss = 1.662807
Round %d: (1, (29.10209837045197, array([467.97777775, 472.86400914])))
Round 2: test_loss = 1.354750
Round %d: (2, (28.351682482087174, array([467.11758531, 475.68618549])))
Round 3: test_loss = 1.107149
Round %d: (3, (26.793889828688172, array([466.17786661, 481.3002062 ])))
Round 4: test_loss = 0.986883
Round %d: (4, (21.6967446704185, array([470.29843136, 489.94829045])))
Round 5: test_loss = 0.891278
Round %d: (5, (16.67715706368028, array([476.65400054, 493.53082649])))
Round 6: test_loss = 0.826683
Round %d: (6, (11.122999781512172, array([484.41564945, 494.91534228])))
Round 7: test_loss = 0.790790
Round %d: (7, (6.920542543553559, array([491.29439421, 493.99930747])))
Round 8: test_loss = 0.757604
Round %d: (8, (5.286862139730298, array([497.59646225, 492.07379405])))
Round 9: test_loss = 0.740656
Round %d: (9, (7.244958148328967, array([501.37788003, 489.2214287 ])))
Round 10: test_loss = 0.737829
Round %d: (10, (8.881454734833461, array([503.68974378, 487.44904029])))
Round 11: test_loss = 0.732488
Round %d: (11, (10.260986222204428, array([505.07891942, 485.89253263])))
Round 12: test_loss = 0.734296
Round %d: (12, (10.500376564303487, array([505.81149402, 485.8454958 ])))
Round 13: test_loss = 0.735038
Round %d: (13, (10.565286822105818, array([505.82398605, 485.75003534])))
Round 14: test_loss = 0.737065
Round %d: (14, (11.208888310423058, array([506.30147459, 484.96866624])))
Round 15: test_loss = 0.733775
Round %d: (15, (11.600657014195182, array([507.34608953, 484.87756129])))
Round 16: test_loss = 0.732069
Round %d: (16, (11.253554210152247, array([506.7279011 , 485.10738313])))
Round 17: test_loss = 0.733306
Round %d: (17, (11.425061500837574, array([507.04436916, 484.99791827])))
Round 18: test_loss = 0.732394
Round %d: (18, (11.277435663867397, array([506.50415901, 484.95841409])))
Round 19: test_loss = 0.735481
Round %d: (19, (11.493854135945547, array([506.1820646 , 484.46987409])))
Round 20: test_loss = 0.733509
Round %d: (20, (11.754892317893503, array([505.79230999, 483.90158117])))
Round 21: test_loss = 0.735505
Round %d: (21, (12.400264716052252, array([506.65185201, 483.27577759])))
Round 22: test_loss = 0.733652
Round %d: (22, (11.969749686202457, array([506.80378479, 484.01601358])))
Round 23: test_loss = 0.735572
Round %d: (23, (12.390633292768893, array([506.7442407 , 483.33215206])))
Round 24: test_loss = 0.731918
Round %d: (24, (12.10161589386987, array([505.88070946, 483.4084855 ])))
Round 25: test_loss = 0.733076
Round %d: (25, (11.4649422524948, array([505.94861122, 484.41175205])))
Round 26: test_loss = 0.732225
Round %d: (26, (11.86506094094835, array([506.08287918, 483.85370222])))
Round 27: test_loss = 0.734133
Round %d: (27, (11.861712449522141, array([506.31697327, 483.96041799])))
Round 28: test_loss = 0.736458
Round %d: (28, (11.949975976627309, array([506.12911113, 483.74286752])))
Round 29: test_loss = 0.739534
Round %d: (29, (11.822345811755277, array([506.10255719, 483.92776363])))
Round 30: test_loss = 0.736019
Round %d: (30, (11.498199224139277, array([507.37450453, 485.0582539 ])))
Round 31: test_loss = 0.734004
Round %d: (31, (11.708323154200693, array([507.21244656, 484.63371267])))
Round 32: test_loss = 0.734699
Round %d: (32, (12.217940265992336, array([507.89446556, 484.1826443 ])))
Round 33: test_loss = 0.735492
Round %d: (33, (12.032404927594987, array([507.41751552, 484.22373755])))
Round 34: test_loss = 0.733174
Round %d: (34, (12.12629162076548, array([507.69495898, 484.22112212])))
Round 35: test_loss = 0.735343
Round %d: (35, (11.773261398996787, array([506.97988791, 484.41131526])))
Round 36: test_loss = 0.736618
Round %d: (36, (11.624879565733176, array([505.95770015, 484.16957272])))
Round 37: test_loss = 0.735665
Round %d: (37, (12.42746758688516, array([506.8089101 , 483.30429963])))
Round 38: test_loss = 0.734193
Round %d: (38, (12.269767354575709, array([507.64403696, 483.96364752])))
Round 39: test_loss = 0.735768
Round %d: (39, (12.804664498181749, array([508.22717483, 483.41859689])))
Closest point in the train dataset to the real location: [503.93417 514.6261 ]
Minimum distance to the real location: 15.95012959699445
  Global Test Loss: 0.7358
  Jammer Initial Localization Error: 30.4235
  Jammer Localization Error: 12.8047
